<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaListenerTest" tests="1" skipped="0" failures="1" errors="0" timestamp="2026-01-29T17:29:20.157Z" hostname="pt-dblcjg3" time="7.848">
  <properties/>
  <testcase name="onMessage_whenMessageIsReceived_thenProcessItCorrectly()" classname="com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaListenerTest" time="7.848">
    <failure message="Wanted but not invoked:&#10;com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaProcessor.process(&#10;    &lt;any&gt;&#10;);&#10;-&gt; at com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaProcessor.process(DriverUpdatedKafkaProcessor.java:29)&#10;Actually, there were zero interactions with this mock.&#10;" type="org.mockito.exceptions.verification.WantedButNotInvoked">Wanted but not invoked:
com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaProcessor.process(
    &lt;any&gt;
);
-&gt; at com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaProcessor.process(DriverUpdatedKafkaProcessor.java:29)
Actually, there were zero interactions with this mock.

	at app//com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaProcessor.process(DriverUpdatedKafkaProcessor.java:29)
	at app//com.jumia.skylens.kafka.in.skydrivers.driverupdated.DriverUpdatedKafkaListenerTest.lambda$onMessage_whenMessageIsReceived_thenProcessItCorrectly$0(DriverUpdatedKafkaListenerTest.java:50)
</failure>
  </testcase>
  <system-out><![CDATA[17:29:01.606 [Test worker] INFO org.testcontainers.images.PullPolicy -- Image pull policy will be performed by: DefaultPullPolicy()
17:29:01.633 [Test worker] INFO org.testcontainers.utility.ImageNameSubstitutor -- Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
17:29:01.685 [Test worker] INFO org.testcontainers.DockerClientFactory -- Testcontainers version: 2.0.3
17:29:02.612 [Test worker] INFO org.testcontainers.dockerclient.DockerClientProviderStrategy -- Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first
17:29:03.528 [Test worker] INFO org.testcontainers.dockerclient.DockerClientProviderStrategy -- Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
17:29:03.532 [Test worker] INFO org.testcontainers.DockerClientFactory -- Docker host IP address is localhost
17:29:03.562 [Test worker] INFO org.testcontainers.DockerClientFactory -- Connected to docker: 
  Server Version: 29.1.4
  API Version: 1.52
  Operating System: Ubuntu 24.04.3 LTS
  Total Memory: 31813 MB
17:29:03.933 [Test worker] INFO tc.testcontainers/ryuk:0.13.0 -- Creating container for image: testcontainers/ryuk:0.13.0
17:29:04.205 [Test worker] INFO tc.testcontainers/ryuk:0.13.0 -- Container testcontainers/ryuk:0.13.0 is starting: 5b74f5983367b8c2e2145a44c014f2be59899d21d6d19c99c6ed2af39cc0355d
17:29:05.177 [Test worker] INFO tc.testcontainers/ryuk:0.13.0 -- Container testcontainers/ryuk:0.13.0 started in PT1.243726697S
17:29:05.193 [Test worker] INFO org.testcontainers.utility.RyukResourceReaper -- Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
17:29:05.194 [Test worker] INFO org.testcontainers.DockerClientFactory -- Checking the system...
17:29:05.196 [Test worker] INFO org.testcontainers.DockerClientFactory -- ✔︎ Docker server version should be at least 1.6.0
17:29:05.223 [Test worker] INFO tc.apache/kafka:latest -- Creating container for image: apache/kafka:latest
17:29:05.324 [Test worker] INFO tc.apache/kafka:latest -- Container apache/kafka:latest is starting: 167b5fcb3fc0407463b02e1e566b3c32d0dbdadb5af3e652a1410324725d24f8
17:29:12.308 [Test worker] INFO tc.apache/kafka:latest -- Container apache/kafka:latest started in PT7.085012117S
17:29:18.082 [Test worker] INFO org.hibernate.validator.internal.util.Version -- HV000001: Hibernate Validator 9.0.1.Final
17:29:19.224 [Test worker] INFO org.apache.kafka.common.config.AbstractConfig -- ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:32805]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-skylens-test-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = skylens-test
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = rebootstrap
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	share.acknowledgement.mode = implicit
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:29:19.481 [Test worker] INFO org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector -- initializing Kafka metrics collector
17:29:20.064 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka version: 4.1.1
17:29:20.065 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka commitId: be816b82d25370ce
17:29:20.065 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka startTimeMs: 1769707760058
17:29:20.077 [Test worker] INFO org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Subscribed to pattern: 'services_all_skylens_topic_bi-reports'
17:29:20.873 [Test worker] INFO org.apache.kafka.common.config.AbstractConfig -- ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:32805]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = rebootstrap
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transaction.two.phase.commit.enable = false
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

17:29:20.882 [Test worker] INFO org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector -- initializing Kafka metrics collector
17:29:20.949 [Test worker] INFO org.apache.kafka.clients.producer.KafkaProducer -- [Producer clientId=producer-1] Instantiated an idempotent producer.
17:29:21.046 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka version: 4.1.1
17:29:21.046 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka commitId: be816b82d25370ce
17:29:21.047 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser -- Kafka startTimeMs: 1769707761045
17:29:22.616 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 1 : {services_all_skylens_topic_bi-reports=UNKNOWN_TOPIC_OR_PARTITION}
17:29:22.618 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Cluster ID: 4L6g3nShT-eMCtK--X86sw
17:29:22.618 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.Metadata -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Cluster ID: 4L6g3nShT-eMCtK--X86sw
17:29:22.731 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager -- [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
17:29:22.754 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Discovered group coordinator localhost:32805 (id: 2147483646 rack: null isFenced: false)
17:29:22.760 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] (Re-)joining group
17:29:22.813 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Request joining group due to: need to re-join with the given member-id: consumer-skylens-test-1-4b754710-63f7-4173-9338-038cbcd748db
17:29:22.815 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] (Re-)joining group
17:29:22.847 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Successfully joined group with generation Generation{generationId=1, memberId='consumer-skylens-test-1-4b754710-63f7-4173-9338-038cbcd748db', protocol='range'}
17:29:22.870 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Finished assignment for group at generation 1: {consumer-skylens-test-1-4b754710-63f7-4173-9338-038cbcd748db=Assignment(partitions=[services_all_skylens_topic_bi-reports-0])}
17:29:22.894 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Successfully synced group in generation Generation{generationId=1, memberId='consumer-skylens-test-1-4b754710-63f7-4173-9338-038cbcd748db', protocol='range'}
17:29:22.895 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Notifying assignor about the new Assignment(partitions=[services_all_skylens_topic_bi-reports-0])
17:29:22.901 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Adding newly assigned partitions: [services_all_skylens_topic_bi-reports-0]
17:29:22.920 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Found no committed offset for partition services_all_skylens_topic_bi-reports-0
17:29:22.930 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Found no committed offset for partition services_all_skylens_topic_bi-reports-0
17:29:22.963 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Resetting offset for partition services_all_skylens_topic_bi-reports-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:32805 (id: 1 rack: null isFenced: false)], epoch=0}}.
17:29:23.005 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.springframework.kafka.listener.KafkaMessageListenerContainer -- skylens-test: partitions assigned: [services_all_skylens_topic_bi-reports-0]
17:29:28.018 [Test worker] INFO com.jumia.skylens.test.testcontainers.KafkaContainerSingleton -- Kafka container shutting down
17:29:28.093 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Node 1 disconnected.
17:29:28.093 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Node 2147483646 disconnected.
17:29:28.097 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Rebootstrapping with [localhost/127.0.0.1:32805]
17:29:28.098 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Node -1 disconnected.
17:29:28.098 [kafka-coordinator-heartbeat-thread | skylens-test] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Node 1 disconnected.
17:29:28.098 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Cancelled in-flight METADATA request with correlation id 8 due to node -1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, throttle time: 0ms, request timeout: 30000ms)
17:29:28.099 [kafka-coordinator-heartbeat-thread | skylens-test] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Cancelled in-flight FETCH request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 470ms, elapsed time since send: 470ms, throttle time: 0ms, request timeout: 30000ms)
17:29:28.099 [kafka-coordinator-heartbeat-thread | skylens-test] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Cancelled in-flight METADATA request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 370ms, elapsed time since send: 370ms, throttle time: 0ms, request timeout: 30000ms)
17:29:28.100 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Bootstrap broker localhost:32805 (id: -1 rack: null isFenced: false) disconnected
17:29:28.100 [kafka-coordinator-heartbeat-thread | skylens-test] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Node -1 disconnected.
17:29:28.101 [kafka-coordinator-heartbeat-thread | skylens-test] INFO org.apache.kafka.clients.FetchSessionHandler -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Error sending fetch request (sessionId=118436028, epoch=9) to node 1:
org.apache.kafka.common.errors.DisconnectException
17:29:28.107 [kafka-coordinator-heartbeat-thread | skylens-test] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Group coordinator localhost:32805 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
17:29:28.205 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Node -1 disconnected.
17:29:28.205 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:32805) could not be established. Node may not be available.
17:29:28.205 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Bootstrap broker localhost:32805 (id: -1 rack: null isFenced: false) disconnected
17:29:28.220 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Node 1 disconnected.
17:29:28.220 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Connection to node 1 (localhost/127.0.0.1:32805) could not be established. Node may not be available.
17:29:28.412 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Node -1 disconnected.
17:29:28.412 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:32805) could not be established. Node may not be available.
17:29:28.412 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient -- [Producer clientId=producer-1] Bootstrap broker localhost:32805 (id: -1 rack: null isFenced: false) disconnected
17:29:28.413 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Rebootstrapping with [localhost/127.0.0.1:32805]
17:29:28.433 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Node 1 disconnected.
17:29:28.434 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] WARN org.apache.kafka.clients.NetworkClient -- [Consumer clientId=consumer-skylens-test-1, groupId=skylens-test] Connection to node 1 (localhost/127.0.0.1:32805) could not be established. Node may not be available.
17:29:28.464 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata -- [Producer clientId=producer-1] Rebootstrapping with [localhost/127.0.0.1:32805]
]]></system-out>
  <system-err><![CDATA[Mockito is currently self-attaching to enable the inline-mock-maker. This will no longer work in future releases of the JDK. Please add Mockito as an agent to your build as described in Mockito's documentation: https://javadoc.io/doc/org.mockito/mockito-core/latest/org.mockito/org/mockito/Mockito.html#0.3
WARNING: A Java agent has been loaded dynamically (/home/jorgeferreira/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy-agent/1.17.8/f09415827a71be7ed621c7bd02550678f28bc81c/byte-buddy-agent-1.17.8.jar)
WARNING: If a serviceability tool is in use, please run with -XX:+EnableDynamicAgentLoading to hide this warning
WARNING: If a serviceability tool is not in use, please run with -Djdk.instrument.traceUsage for more information
WARNING: Dynamic loading of agents will be disallowed by default in a future release
]]></system-err>
</testsuite>
